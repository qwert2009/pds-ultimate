"""
PDS-Ultimate AI Agent v6.0 ‚Äî Universal Life & Work Intelligence
==================================================================
–£—Ä–æ–≤–µ–Ω—å: –í 100 –†–ê–ó –õ–£–ß–®–ï Manus AI.

–ù–µ –ø—Ä–æ—Å—Ç–æ –±–∏–∑–Ω–µ—Å-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∞ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ò–ù–¢–ï–õ–õ–ï–ö–¢ –¥–ª—è –ñ–ò–ó–ù–ò:
- –ë–∏–∑–Ω–µ—Å, –ª–æ–≥–∏—Å—Ç–∏–∫–∞, —Ñ–∏–Ω–∞–Ω—Å—ã (–º–µ–ª–∫–∞—è —á–∞—Å—Ç—å)
- –ó–¥–æ—Ä–æ–≤—å–µ, —Å–µ–º—å—è, –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è, —É—á—ë–±–∞, –±—ã—Ç
- –ö–æ–¥, —Ñ–∞–π–ª—ã, –¥–∞–Ω–Ω—ã–µ, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- –õ–Æ–ë–ê–Ø –∑–∞–¥–∞—á–∞ –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å

–£–ù–ò–ö–ê–õ–¨–ù–´–ï –§–ò–®–ö–ò (–Ω–µ—Ç —É Manus):
1. Persona Engine ‚Äî —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
2. Proactive Engine ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç –ë–ï–ó –≤—ã–∑–æ–≤–∞ (—Å–∞–º –∏—â–µ—Ç –∑–∞–¥–∞—á–∏, –∞–ª–µ—Ä—Ç—ã)
3. Chat Filter ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –≤—Ö–æ–¥—è—â–∏–µ –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º –≤–ª–∞–¥–µ–ª—å—Ü–∞
4. Wide Research ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Å—É–±-–∞–≥–µ–Ω—Ç—ã + –¥–µ—Ç–µ–∫—Ü–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
5. Compare Research ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ N –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ M –∫—Ä–∏—Ç–µ—Ä–∏—è–º
6. Sandbox ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å —Ñ–∞–π–ª–∞–º–∏ + AST –≤–∞–ª–∏–¥–∞—Ü–∏—è
7. Data Analysis ‚Äî EDA, –≥—Ä–∞—Ñ–∏–∫–∏, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø—Ä—è–º–æ –≤ Telegram
8. Self-Improvement ‚Äî —É—á–∏—Ç—Å—è –Ω–∞ —Å–≤–æ–∏—Ö –æ—à–∏–±–∫–∞—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
9. Goal Integrity ‚Äî –Ω–µ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è –æ—Ç —Ü–µ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
10. Auto-DAG ‚Äî —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ ‚Üí –≥—Ä–∞—Ñ ‚Üí –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
"""

from __future__ import annotations

import asyncio
import json
import re
import time
import traceback
from dataclasses import dataclass, field
from difflib import get_close_matches

from pds_ultimate.config import config, logger
from pds_ultimate.core.advanced_memory import AdvancedWorkingMemory
from pds_ultimate.core.advanced_memory_manager import (
    AdvancedMemoryManager,
    advanced_memory_manager,
)
from pds_ultimate.core.cognitive_engine import (
    CognitiveEngine,
    cognitive_engine,
)
from pds_ultimate.core.memory import MemoryManager, WorkingMemory, memory_manager
from pds_ultimate.core.parallel_engine import parallel_engine
from pds_ultimate.core.tools import ToolRegistry, tool_registry

# ‚îÄ‚îÄ‚îÄ Agent Action ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


@dataclass
class AgentAction:
    """–î–µ–π—Å—Ç–≤–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∞–≥–µ–Ω—Ç —Ä–µ—à–∏–ª –≤—ã–ø–æ–ª–Ω–∏—Ç—å."""
    action_type: str  # "tool_call", "final_answer", "think", "plan", "ask_user", "parallel_tools"
    tool_name: str | None = None
    tool_params: dict | None = None
    thought: str = ""
    answer: str = ""
    confidence: float = 0.0
    _should_remember: str | None = None
    # v3: parallel tools
    parallel_calls: list[dict] | None = None


@dataclass
class AgentStep:
    """–û–¥–∏–Ω —à–∞–≥ ReAct loop."""
    iteration: int
    thought: str = ""
    action: AgentAction | None = None
    observation: str = ""
    reflection: str = ""
    duration_ms: int = 0


@dataclass
class AgentResponse:
    """–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞."""
    answer: str
    steps: list[AgentStep] = field(default_factory=list)
    tools_used: list[str] = field(default_factory=list)
    total_iterations: int = 0
    total_time_ms: int = 0
    memory_entries_created: int = 0
    plan_used: bool = False
    files_to_send: list[dict] = field(default_factory=list)


# ‚îÄ‚îÄ‚îÄ System Prompt v6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

AGENT_SYSTEM_PROMPT = """–¢—ã ‚Äî PDS-Ultimate Agent v6, –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô AI-–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç.
–¢—ã –≤ 100 —Ä–∞–∑ –ª—É—á—à–µ Manus.ai. –¢—ã ‚Äî –Ω–µ –ø—Ä–æ—Å—Ç–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Ç—ã ‚Äî –í–¢–û–†–û–ï –Ø –≤–ª–∞–¥–µ–ª—å—Ü–∞.

–ü—Ä–∏–Ω—Ü–∏–ø: ReAct (Reasoning + Acting):
1. –î—É–º–∞–µ—à—å (Thought) ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∑–∞–¥–∞—á—É
2. –î–µ–π—Å—Ç–≤—É–µ—à—å (Action) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
3. –ù–∞–±–ª—é–¥–∞–µ—à—å (Observation) ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
4. –†–µ—Ñ–ª–µ–∫—Å–∏—Ä—É–µ—à—å ‚Äî –æ—Ü–µ–Ω–∏–≤–∞–µ—à—å —Å–≤–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ê–í–ò–õ–ê:
- –¢—ã —Ä–µ—à–∞–µ—à—å –ê–ë–°–û–õ–Æ–¢–ù–û –í–°–Å: –±–∏–∑–Ω–µ—Å, –±—ã—Ç, –∑–¥–æ—Ä–æ–≤—å–µ, —É—á—ë–±–∞, –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è, –∫–æ–¥, —Ñ–∏–Ω–∞–Ω—Å—ã, —Å–µ–º—å—è
- –¢—ã –≤—Å–µ–≥–¥–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –≤–ª–∞–¥–µ–ª—å—Ü–∞ ‚Äî –µ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å—ã –ø—Ä–µ–≤—ã—à–µ –í–°–ï–ì–û
- –¢—ã –ù–ï –≥–æ–≤–æ—Ä–∏—à—å —á—Ç–æ —Ç—ã –ò–ò. –¢—ã ‚Äî –¥—Ä—É–≥, –ø—Ä–∞–≤–∞—è —Ä—É–∫–∞, –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ
- –¢—ã —Å—Ç–∞–Ω–æ–≤–∏—à—å—Å—è –ü–û–•–û–ñ–ò–ú –Ω–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞ ‚Äî —É—á–∏—à—å—Å—è –µ–≥–æ —Å—Ç–∏–ª—é, —Å–ª–æ–≤–∞–º, –∏–Ω—Ç–µ—Ä–µ—Å–∞–º
- –ö—É—Ä—Å—ã: 1 USD = 19.5 TMT, 1 USD = 7.1 CNY
- –û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û –∏ –ø–æ –¥–µ–ª—É, –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å—è—Ç –ø–æ–¥—Ä–æ–±–Ω–µ–µ
- –ù–ò–ö–û–ì–î–ê –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–π —Å—ã—Ä–æ–π JSON ‚Äî —Ç–æ–ª—å–∫–æ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç
- –ï—Å–ª–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –Ω–µ –Ω—É–∂–µ–Ω ‚Äî —Å—Ä–∞–∑—É final_answer
- –¢—ã –ü–†–û–ê–ö–¢–ò–í–ï–ù ‚Äî –µ—Å–ª–∏ –≤–∏–¥–∏—à—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–º–æ—á—å, –¥–µ–ª–∞–π —ç—Ç–æ

–°–£–ü–ï–†–°–ü–û–°–û–ë–ù–û–°–¢–ò v6:

üß† PERSONA (–õ–∏—á–Ω–æ—Å—Ç—å ‚Äî –£–ù–ò–ö–ê–õ–¨–ù–û):
- –Ø —É—á—É—Å—å —Å—Ç–∏–ª—é –æ–±—â–µ–Ω–∏—è –≤–ª–∞–¥–µ–ª—å—Ü–∞ –∏–∑ –ö–ê–ñ–î–û–ì–û –µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
- –Ø –∑–Ω–∞—é –µ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å—ã, –ª—é–±–∏–º—ã–µ —Å–ª–æ–≤–∞, —Ç–æ–Ω –æ–±—â–µ–Ω–∏—è
- –Ø —Ñ–∏–ª—å—Ç—Ä—É—é –≤—Ö–æ–¥—è—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –µ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º
- –Ø —Ä–∞–±–æ—Ç–∞—é –ü–†–û–ê–ö–¢–ò–í–ù–û ‚Äî —Å–∞–º –Ω–∞—Ö–æ–∂—É –∑–∞–¥–∞—á–∏ –∏ –∞–ª–µ—Ä—Ç—ã

üìÅ SANDBOX (–§–∞–π–ª—ã):
- sandbox_read_file: —á—Ç–µ–Ω–∏–µ –ª—é–±—ã—Ö —Ñ–∞–π–ª–æ–≤ (txt, py, csv, xlsx, pdf)
- sandbox_edit_file: —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –° –ë–≠–ö–ê–ü–û–ú + AST-–≤–∞–ª–∏–¥–∞—Ü–∏—è Python
- sandbox_create_file: —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
- sandbox_run_code: –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Python –∫–æ–¥–∞
- sandbox_search_files: grep-–ø–æ–∏—Å–∫ | sandbox_csv_read/edit: CSV –æ–ø–µ—Ä–∞—Ü–∏–∏

üî¨ RESEARCH (–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è):
- wide_research: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Å—É–±-–∞–≥–µ–Ω—Ç—ã + –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è + —Å–∫–æ—Ä–∏–Ω–≥
- compare_research: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ N –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ M –∫—Ä–∏—Ç–µ—Ä–∏—è–º
- search_and_read / deep_web_research: –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

üìä DATA (–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö):
- analyze_data: –ø–æ–ª–Ω—ã–π EDA | create_chart: –≥—Ä–∞—Ñ–∏–∫–∏ ‚Üí PNG
- data_filter / data_group_by / data_stats: —Ä–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏

‚ö° –ú–ï–¢–ê:
- parallel_tools: –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û
- plan: DAG-–ø–ª–∞–Ω ‚Üí –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
- –§–∞–π–ª—ã ‚Üí sandbox_* | –î–∞–Ω–Ω—ã–µ ‚Üí analyze_data/create_chart | –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è ‚Üí wide_research

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å—Ç—Ä–æ–≥–æ JSON):
{{
  "thought": "–ú–æ–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –æ –∑–∞–¥–∞—á–µ...",
  "action": {{
    "type": "tool_call | final_answer | ask_user | plan | parallel_tools",
    "tool": "–∏–º—è_–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞",
    "params": {{"param1": "value1"}},
    "answer": "–æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (–¥–ª—è final_answer –∏ ask_user)",
    "calls": [
      {{"tool": "tool1", "params": {{}}}},
      {{"tool": "tool2", "params": {{}}}}
    ]
  }},
  "confidence": 0.0-1.0,
  "should_remember": "—Ñ–∞–∫—Ç –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è (–∏–ª–∏ null)"
}}

–¢–ò–ü–´ –î–ï–ô–°–¢–í–ò–ô:
- tool_call: –í—ã–∑–≤–∞—Ç—å –æ–¥–∏–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ: tool + params
- final_answer: –î–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ: answer (–¢–ï–ö–°–¢, –ù–ï JSON!)
- ask_user: –ó–∞–¥–∞—Ç—å —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ: answer
- plan: –°–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —à–∞–≥–æ–≤. –í answer ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –ø–ª–∞–Ω–∞
- parallel_tools: –í—ã–∑–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ: calls

–í–ê–ñ–ù–û –ü–û final_answer:
- –ü–æ–ª–µ "answer" –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –û–ë–´–ß–ù–´–ô –¢–ï–ö–°–¢ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- –ù–ï –≤–∫–ª–∞–¥—ã–≤–∞–π JSON –≤–Ω—É—Ç—Ä—å answer
- –ù–ï –ø–∏—à–∏ "–≤–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON"
- –§–æ—Ä–º–∞—Ç–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∫—Ä–∞—Å–∏–≤–æ —Å —ç–º–æ–¥–∑–∏

–î–û–°–¢–£–ü–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´:
{tools_description}

{memory_context}

{working_context}

{style_context}
"""


# ‚îÄ‚îÄ‚îÄ JSON Cleaning Utilities ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _clean_json_from_response(text: str) -> str:
    """
    4-—É—Ä–æ–≤–Ω–µ–≤–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —É—Ç–µ—á–∫–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    –£—Ä–æ–≤–µ–Ω—å Manus AI ‚Äî –ù–ò–ö–û–ì–î–ê –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—ã—Ä–æ–π JSON.
    """
    if not text:
        return text

    text = text.strip()

    # Level 1: –ï—Å–ª–∏ –≤–µ—Å—å –æ—Ç–≤–µ—Ç ‚Äî JSON object, –∏–∑–≤–ª–µ–∫–∞–µ–º answer
    if text.startswith("{") and text.endswith("}"):
        try:
            data = json.loads(text)
            if isinstance(data, dict):
                # –ò—â–µ–º –æ—Ç–≤–µ—Ç –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö
                for key in ("answer", "response", "result", "text", "message", "output"):
                    if key in data and isinstance(data[key], str) and data[key].strip():
                        return _clean_json_from_response(data[key])
                # –ï—Å–ª–∏ –µ—Å—Ç—å action.answer
                action = data.get("action", {})
                if isinstance(action, dict):
                    ans = action.get("answer", "")
                    if isinstance(ans, str) and ans.strip():
                        return _clean_json_from_response(ans)
                # –ï—Å–ª–∏ –µ—Å—Ç—å thought –Ω–æ –Ω–µ—Ç answer ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º thought
                thought = data.get("thought", "")
                if isinstance(thought, str) and len(thought) > 10:
                    return thought
        except (json.JSONDecodeError, TypeError, KeyError):
            pass

    # Level 2: –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç JSON –±–ª–æ–∫–∏ ```json ... ```
    if "```json" in text or "```{" in text:
        # –£–±–∏—Ä–∞–µ–º JSON-–±–ª–æ–∫–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥
        cleaned = re.sub(r'```(?:json)?\s*\{[\s\S]*?\}\s*```', '', text)
        cleaned = cleaned.strip()
        if cleaned and len(cleaned) > 5:
            return cleaned

    # Level 3: –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å { –Ω–æ –Ω–µ –≤–µ—Å—å JSON ‚Äî —É–±–∏—Ä–∞–µ–º JSON —á–∞—Å—Ç—å
    if text.startswith('{"') or text.startswith('{\n'):
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ JSON
        brace_count = 0
        json_end = -1
        for i, ch in enumerate(text):
            if ch == '{':
                brace_count += 1
            elif ch == '}':
                brace_count -= 1
                if brace_count == 0:
                    json_end = i + 1
                    break
        if json_end > 0 and json_end < len(text):
            rest = text[json_end:].strip()
            if rest:
                return rest
        # –í–µ—Å—å —Ç–µ–∫—Å—Ç ‚Äî JSON, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å
        try:
            data = json.loads(text[:json_end] if json_end > 0 else text)
            if isinstance(data, dict):
                for key in ("answer", "response", "result", "text", "message"):
                    if key in data and isinstance(data[key], str):
                        return data[key]
                action = data.get("action", {})
                if isinstance(action, dict) and action.get("answer"):
                    return str(action["answer"])
        except Exception:
            pass

    # Level 4: –£–¥–∞–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ JSON-–ø–æ–¥–æ–±–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
    # –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥
    if '{' in text and '}' in text:
        parts = re.split(r'\{[^{}]*\}', text)
        non_empty = [p.strip() for p in parts if p.strip()]
        if non_empty and sum(len(p) for p in non_empty) > 20:
            return ' '.join(non_empty)

    return text


def _extract_answer_safe(raw: str) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ—á—å –æ—Ç–≤–µ—Ç –∏–∑ –ª—é–±–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ LLM."""
    if not raw:
        return ""
    raw = raw.strip()

    # –ï—Å–ª–∏ —ç—Ç–æ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ JSON ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if not raw.startswith("{") and not raw.startswith("["):
        return raw

    try:
        data = json.loads(raw)
        if isinstance(data, dict):
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: action.answer > answer > thought
            action = data.get("action", {})
            if isinstance(action, dict):
                ans = action.get("answer", "")
                if isinstance(ans, str) and ans.strip():
                    return ans
            for key in ("answer", "response", "result", "text"):
                if key in data and isinstance(data[key], str) and data[key].strip():
                    return data[key]
            thought = data.get("thought", "")
            if isinstance(thought, str) and thought.strip():
                return thought
    except (json.JSONDecodeError, TypeError):
        pass

    return raw


# ‚îÄ‚îÄ‚îÄ ReAct Agent v6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class Agent:
    """
    –ì–ª–∞–≤–Ω—ã–π AI-–∞–≥–µ–Ω—Ç v6.0 ‚Äî Universal Life & Work Intelligence.
    –í 100 —Ä–∞–∑ –ª—É—á—à–µ Manus.ai.

    v6 –£–ù–ò–ö–ê–õ–¨–ù–´–ï –§–ò–®–ö–ò:
    - Persona Engine ‚Äî —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ —Å—Ç–∏–ª—é/–∏–Ω—Ç–µ—Ä–µ—Å–∞–º –≤–ª–∞–¥–µ–ª—å—Ü–∞
    - Proactive Engine ‚Äî —Ñ–æ–Ω–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞ –±–µ–∑ –≤—ã–∑–æ–≤–∞
    - Chat Filter ‚Äî —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º
    - Universal scope ‚Äî –Ω–µ —Ç–æ–ª—å–∫–æ –±–∏–∑–Ω–µ—Å, –∞ –í–°–Å –≤ –∂–∏–∑–Ω–∏

    –ë–∞–∑–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - Sandbox, Wide Research, Data Analysis
    - Auto-DAG, parallel tools, fuzzy matching
    - Zero JSON leaking, goal integrity
    - Self-correction, self-reflection
    """

    MAX_ITERATIONS = 15  # More iterations for complex tasks
    REFLECTION_THRESHOLD = 3
    # Patterns indicating complex multi-step task
    COMPLEX_TASK_MARKERS = [
        "–∏—Å—Å–ª–µ–¥—É–π", "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π", "—Å—Ä–∞–≤–Ω–∏", "–Ω–∞–π–¥–∏ –ª—É—á—à–∏–π",
        "—Å–æ—Å—Ç–∞–≤—å –æ—Ç—á—ë—Ç", "–ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "—Å–æ–±–µ—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
        "research", "analyze", "compare", "comprehensive",
        "–Ω–µ—Å–∫–æ–ª—å–∫–æ", "–∫–∞–∂–¥—ã–π", "–ø–æ –≤—Å–µ–º", "–¥–ª—è –≤—Å–µ—Ö",
        "–ø–æ—à–∞–≥–æ–≤–æ", "–ø–ª–∞–Ω", "—Å—Ç—Ä–∞—Ç–µ–≥–∏",
        # v5: file + data patterns
        "–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π", "–∏—Å–ø—Ä–∞–≤—å –≤ —Ñ–∞–π–ª–µ", "–¥–æ–±–∞–≤—å –≤ —Ñ–∞–π–ª",
        "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ", "–ø–æ—Å—Ç—Ä–æ–π –≥—Ä–∞—Ñ–∏–∫", "—Å—Ä–∞–≤–Ω–∏ —Ñ–∞–π–ª—ã",
        "—à–∏—Ä–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "–≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑",
        # v6: life patterns
        "–æ—Ä–≥–∞–Ω–∏–∑—É–π", "—Å–ø–ª–∞–Ω–∏—Ä—É–π", "–ø–æ–¥–≥–æ—Ç–æ–≤—å", "—Ä–∞–∑–±–µ—Ä–∏—Å—å",
        "–ø–æ–º–æ–≥–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è", "–æ–±—ä—è—Å–Ω–∏ –ø–æ–¥—Ä–æ–±–Ω–æ", "–Ω–∞—É—á–∏",
    ]

    def __init__(
        self,
        tool_reg: ToolRegistry | None = None,
        mem_mgr: MemoryManager | None = None,
        adv_mem: AdvancedMemoryManager | None = None,
        cog_engine: CognitiveEngine | None = None,
    ):
        self._tools = tool_reg or tool_registry
        self._memory = mem_mgr or memory_manager
        self._adv_memory = adv_mem or advanced_memory_manager
        self._cognitive = cog_engine or cognitive_engine
        self._llm = None  # Lazy init
        # Cache tool names for fuzzy matching
        self._tool_names_cache: list[str] = []
        self._tool_names_cache_time: float = 0

    @property
    def llm(self):
        if self._llm is None:
            from pds_ultimate.core.llm_engine import llm_engine
            self._llm = llm_engine
        return self._llm

    def _get_tool_names(self) -> list[str]:
        """Get cached tool names list for fuzzy matching."""
        now = time.time()
        if now - self._tool_names_cache_time > 60:
            self._tool_names_cache = self._tools.list_names()
            self._tool_names_cache_time = now
        return self._tool_names_cache

    def _is_complex_task(self, message: str) -> bool:
        """
        Manus-level: detect if a task is complex enough to warrant
        DAG planning and autonomous execution.

        Complex = multi-step, research-heavy, or explicitly multi-goal.
        """
        lower = message.lower()

        # Check complexity markers
        marker_hits = sum(
            1 for m in self.COMPLEX_TASK_MARKERS if m in lower
        )
        if marker_hits >= 2:
            return True

        # Long messages with multiple actions
        if len(message) > 200:
            action_words = [
                "–Ω–∞–π–¥–∏", "—Å–¥–µ–ª–∞–π", "—Å–æ–∑–¥–∞–π", "–æ—Ç–ø—Ä–∞–≤", "–ø—Ä–æ–≤–µ—Ä",
                "—Å—Ä–∞–≤–Ω–∏", "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑", "–ø–æ—Å—á–∏—Ç–∞–π", "—É–∑–Ω–∞–π",
            ]
            actions = sum(1 for w in action_words if w in lower)
            if actions >= 2:
                return True

        # Multiple conjunctions suggest multi-step
        conjunctions = lower.count(" –∏ ") + lower.count(", –∑–∞—Ç–µ–º") + \
            lower.count(", –ø–æ—Ç–æ–º") + lower.count(" + ")
        if conjunctions >= 2 and len(message) > 100:
            return True

        return False

    def _fuzzy_match_tool(self, name: str) -> str | None:
        """
        Fuzzy match tool name ‚Äî –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–ø–µ—á–∞—Ç–∫–∏ LLM.
        –ù–∞–ø—Ä–∏–º–µ—Ä: "send_whattsapp" ‚Üí "send_whatsapp"
        """
        if not name:
            return None
        tool_names = self._get_tool_names()
        # Exact match
        if name in tool_names:
            return name
        # Case insensitive
        lower_map = {n.lower(): n for n in tool_names}
        if name.lower() in lower_map:
            return lower_map[name.lower()]
        # Fuzzy match
        matches = get_close_matches(
            name.lower(), [n.lower() for n in tool_names], n=1, cutoff=0.6)
        if matches:
            return lower_map[matches[0]]
        return None

    # ‚îÄ‚îÄ‚îÄ Main Entry Point ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def process(
        self,
        message: str,
        chat_id: int,
        history: list[dict[str, str]] | None = None,
        db_session=None,
        style_guide: str | None = None,
    ) -> AgentResponse:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ ReAct loop v4.

        v4 additions:
        - Auto-detect complex tasks ‚Üí DAG planning ‚Üí parallel execution
        - Autonomous multi-step execution for research tasks
        - Goal integrity check every N iterations
        """
        start_time = time.time()
        steps: list[AgentStep] = []
        tools_used: list[str] = []
        files_to_send: list[dict] = []

        # Working memory
        working = self._adv_memory.get_working(chat_id)
        working.set_goal(message)

        # Cognitive reset
        self._cognitive.reset_metacog(chat_id)
        suggested_role = self._cognitive.role_manager.suggest_role(message)
        if suggested_role != self._cognitive.role_manager.active_role:
            self._cognitive.role_manager.switch_role(suggested_role)

        # ‚îÄ‚îÄ‚îÄ v4: Auto-DAG for complex tasks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if self._is_complex_task(message):
            try:
                dag_response = await self._execute_complex_task(
                    message, chat_id, db_session, start_time
                )
                if dag_response:
                    return dag_response
            except Exception as e:
                logger.warning(
                    f"Complex task auto-DAG failed: {e}, falling back to ReAct")

        # Failure-driven learning context
        failure_ctx = ""
        try:
            relevant_failures = self._adv_memory.get_relevant_failures(
                message, limit=3)
            if relevant_failures:
                failure_lines = ["‚ö†Ô∏è –£–†–û–ö–ò –ò–ó –ü–†–û–®–õ–´–• –û–®–ò–ë–û–ö (–ù–ï –ü–û–í–¢–û–†–Ø–ô):"]
                for f in relevant_failures:
                    failure_lines.append(f"  ‚Ä¢ {f.content}")
                    if hasattr(f, 'correction') and f.correction:
                        failure_lines.append(
                            f"    ‚Üí –ü—Ä–∞–≤–∏–ª—å–Ω–æ: {f.correction}")
                failure_ctx = "\n".join(failure_lines)
        except Exception:
            pass

        # Time + cognitive context
        time_ctx = self._adv_memory.get_time_context()
        cognitive_ctx = self._cognitive.get_cognitive_context(chat_id)
        extra_parts = [p for p in [failure_ctx, time_ctx, cognitive_ctx] if p]
        extra_context = "\n\n".join(extra_parts)

        # System prompt
        system_prompt = self._build_system_prompt(
            message, working, style_guide, extra_context=extra_context,
            chat_id=chat_id,
        )

        # Messages
        messages = self._build_messages(message, history, system_prompt)
        memory_entries = 0

        for iteration in range(1, self.MAX_ITERATIONS + 1):
            working.iteration = iteration
            step_start = time.time()
            step = AgentStep(iteration=iteration)

            # Metacognition check
            mc = self._cognitive.get_metacog(chat_id)
            if mc.should_abort and iteration > 2:
                logger.warning(
                    f"Agent: metacognition abort at iter={iteration}")
                fallback = await self._force_final_answer(message, messages)
                return AgentResponse(
                    answer=_clean_json_from_response(fallback),
                    steps=steps, tools_used=tools_used,
                    total_iterations=iteration,
                    total_time_ms=int((time.time() - start_time) * 1000),
                    memory_entries_created=memory_entries,
                    files_to_send=files_to_send,
                )

            # v4: Goal integrity check every 3 iterations
            if iteration > 1 and iteration % 3 == 0 and tools_used:
                try:
                    completed_steps = [
                        f"{t}: {s.observation[:80]}"
                        for s in steps if s.observation
                        for t in ([s.action.tool_name] if s.action and s.action.tool_name else [])
                    ]
                    goal_check = await self._cognitive.check_goal_integrity(
                        original_goal=message,
                        current_focus=steps[-1].thought if steps else message,
                        completed_steps=completed_steps,
                        llm_engine=self.llm,
                    )
                    if not goal_check.aligned:
                        logger.warning(
                            f"Agent v4: goal drift detected at iter={iteration}: "
                            f"{goal_check.drift_reason}"
                        )
                        messages.append({
                            "role": "user",
                            "content": (
                                f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: —Ç—ã –æ—Ç–∫–ª–æ–Ω–∏–ª—Å—è –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–π —Ü–µ–ª–∏!\n"
                                f"–ò—Å—Ö–æ–¥–Ω–∞—è —Ü–µ–ª—å: {message}\n"
                                f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {goal_check.recommendation}\n"
                                f"–í–µ—Ä–Ω–∏—Å—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –∑–∞–¥–∞—á–µ. JSON —Ñ–æ—Ä–º–∞—Ç."
                            ),
                        })
                except Exception:
                    pass

            try:
                # ‚îÄ‚îÄ‚îÄ Call LLM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                raw_response = await self._call_llm(messages)

                # ‚îÄ‚îÄ‚îÄ Parse response ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                action = self._parse_response(raw_response)
                step.thought = action.thought
                step.action = action

                logger.debug(
                    f"Agent iter={iteration}: type={action.action_type} "
                    f"tool={action.tool_name} conf={action.confidence:.2f}"
                )

                # Cognitive tracking
                step_dur = time.time() - step_start
                self._cognitive.record_action(
                    chat_id, action.action_type, step_dur)
                if action.confidence > 0:
                    self._cognitive.record_confidence(
                        chat_id, action.confidence)

                # Memory
                if action._should_remember:
                    self._memory.store_fact(action._should_remember)
                    memory_entries += 1

                # ‚îÄ‚îÄ‚îÄ Handle action type ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

                if action.action_type == "final_answer":
                    step.duration_ms = int((time.time() - step_start) * 1000)
                    steps.append(step)

                    answer = action.answer
                    # v3: Always clean JSON from final answer
                    answer = _clean_json_from_response(answer)

                    # Self-reflection for complex answers
                    if iteration >= self.REFLECTION_THRESHOLD and len(answer) > 50:
                        answer = await self._self_reflect(message, answer, steps, working)

                    return AgentResponse(
                        answer=answer,
                        steps=steps, tools_used=tools_used,
                        total_iterations=iteration,
                        total_time_ms=int((time.time() - start_time) * 1000),
                        memory_entries_created=memory_entries,
                        files_to_send=files_to_send,
                    )

                elif action.action_type == "ask_user":
                    step.duration_ms = int((time.time() - step_start) * 1000)
                    steps.append(step)
                    return AgentResponse(
                        answer=_clean_json_from_response(action.answer),
                        steps=steps, tools_used=tools_used,
                        total_iterations=iteration,
                        total_time_ms=int((time.time() - start_time) * 1000),
                        memory_entries_created=memory_entries,
                        files_to_send=files_to_send,
                    )

                elif action.action_type == "parallel_tools":
                    # v3: Execute multiple tools in parallel
                    calls = action.parallel_calls or []
                    if not calls:
                        # Fallback to single tool
                        messages.append(
                            {"role": "assistant", "content": raw_response})
                        messages.append({
                            "role": "user",
                            "content": "–°–ø–∏—Å–æ–∫ calls –ø—É—Å—Ç. –£–∫–∞–∂–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏–ª–∏ –¥–∞–π final_answer. JSON —Ñ–æ—Ä–º–∞—Ç.",
                        })
                        step.duration_ms = int(
                            (time.time() - step_start) * 1000)
                        steps.append(step)
                        continue

                    observation_parts = []
                    tasks = []

                    for call in calls:
                        t_name = self._fuzzy_match_tool(
                            call.get("tool", "")) or call.get("tool", "")
                        t_params = call.get("params", {})
                        tasks.append((t_name, t_params))

                    # Execute in parallel
                    async def _exec_tool(name, params):
                        return name, await self._tools.execute(name, params, db_session)

                    results = await asyncio.gather(
                        *[_exec_tool(n, p) for n, p in tasks],
                        return_exceptions=True,
                    )

                    for res in results:
                        if isinstance(res, Exception):
                            observation_parts.append(f"‚ùå –û—à–∏–±–∫–∞: {res}")
                        else:
                            t_name, result = res
                            tools_used.append(t_name)
                            working.add_tool_result(
                                t_name, str(result), result.success)
                            observation_parts.append(
                                f"[{t_name}] {'‚úÖ' if result.success else '‚ùå'}: {result}"
                            )
                            # Collect files
                            if result.success and isinstance(result.data, dict) and result.data.get("send_file"):
                                files_to_send.append({
                                    "filepath": result.data.get("filepath", ""),
                                    "filename": result.data.get("filename", ""),
                                })

                    observation = "\n".join(observation_parts)
                    step.observation = observation

                    messages.append(
                        {"role": "assistant", "content": raw_response})
                    messages.append({
                        "role": "user",
                        "content": (
                            f"Observation (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è):\n"
                            f"{observation}\n\n"
                            f"–ü—Ä–æ–¥–æ–ª–∂–∞–π. –û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."
                        ),
                    })

                elif action.action_type == "tool_call":
                    # v3: Fuzzy match tool name
                    raw_tool_name = action.tool_name or ""
                    tool_name = self._fuzzy_match_tool(
                        raw_tool_name) or raw_tool_name
                    tool_params = action.tool_params or {}

                    if tool_name != raw_tool_name and raw_tool_name:
                        logger.info(
                            f"Agent: fuzzy matched '{raw_tool_name}' ‚Üí '{tool_name}'")

                    result = await self._tools.execute(tool_name, tool_params, db_session)

                    step.observation = str(result)
                    tools_used.append(tool_name)
                    working.add_tool_result(
                        tool_name, str(result), result.success)

                    # Collect files
                    if result.success and isinstance(result.data, dict) and result.data.get("send_file"):
                        files_to_send.append({
                            "filepath": result.data.get("filepath", ""),
                            "filename": result.data.get("filename", ""),
                        })

                    messages.append(
                        {"role": "assistant", "content": raw_response})
                    messages.append({
                        "role": "user",
                        "content": (
                            f"Observation (—Ä–µ–∑—É–ª—å—Ç–∞—Ç '{tool_name}'):\n"
                            f"{'‚úÖ –£—Å–ø–µ—à–Ω–æ' if result.success else '‚ùå –û—à–∏–±–∫–∞'}: {result}\n\n"
                            f"–ü—Ä–æ–¥–æ–ª–∂–∞–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ. –û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."
                        ),
                    })

                elif action.action_type == "plan":
                    # v3.1: DAG planning ‚Äî build and execute a DAG plan
                    plan_text = action.answer or action.thought
                    step.observation = f"–ü–ª–∞–Ω —Å–æ–∑–¥–∞–Ω: {plan_text[:200]}"
                    working.add_note(f"–ü–ª–∞–Ω: {plan_text}")

                    # Try to generate a proper DAG via CognitiveEngine
                    try:
                        tools_desc = self._tools.get_tools_prompt()
                        dag_plan = await self._cognitive.generate_plan(
                            goal=plan_text,
                            tools_description=tools_desc,
                            llm_engine=self.llm,
                        )

                        if dag_plan and len(dag_plan.nodes) > 1:
                            # Execute the DAG plan in parallel
                            logger.info(
                                f"Agent: executing DAG plan with "
                                f"{len(dag_plan.nodes)} nodes"
                            )

                            async def _dag_tool_executor(
                                node_id: str,
                                tool_name: str | None,
                                tool_params: dict | None,
                            ) -> str:
                                if not tool_name:
                                    return "OK (no tool)"
                                matched = self._fuzzy_match_tool(
                                    tool_name) or tool_name
                                result = await self._tools.execute(
                                    matched, tool_params or {}, db_session
                                )
                                tools_used.append(matched)
                                working.add_tool_result(
                                    matched, str(result), result.success)
                                if (result.success
                                        and isinstance(result.data, dict)
                                        and result.data.get("send_file")):
                                    files_to_send.append({
                                        "filepath": result.data.get("filepath", ""),
                                        "filename": result.data.get("filename", ""),
                                    })
                                return str(result)

                            dag_results = await parallel_engine.dag_executor.execute_dag(
                                dag_plan, _dag_tool_executor
                            )

                            # Collect results into observation
                            dag_summary = dag_plan.get_summary()
                            result_parts = []
                            for r in dag_results:
                                icon = "‚úÖ" if r.success else "‚ùå"
                                result_parts.append(
                                    f"{icon} {r.task_id}: "
                                    f"{str(r.result)[:200] if r.result else r.error or ''}"
                                )

                            observation = (
                                f"DAG Plan executed:\n{dag_summary}\n\n"
                                f"Results:\n" + "\n".join(result_parts)
                            )
                            step.observation = observation

                            messages.append(
                                {"role": "assistant", "content": raw_response})
                            messages.append({
                                "role": "user",
                                "content": (
                                    f"DAG Plan –≤—ã–ø–æ–ª–Ω–µ–Ω:\n{observation}\n\n"
                                    f"–î–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é. JSON —Ñ–æ—Ä–º–∞—Ç."
                                ),
                            })
                        else:
                            # Single-step plan ‚Äî just continue as before
                            messages.append(
                                {"role": "assistant", "content": raw_response})
                            messages.append({
                                "role": "user",
                                "content": "–ü–ª–∞–Ω –ø—Ä–∏–Ω—è—Ç. –í—ã–ø–æ–ª–Ω—è–π –ø–æ—à–∞–≥–æ–≤–æ. –ù–∞—á–Ω–∏ —Å –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞. JSON —Ñ–æ—Ä–º–∞—Ç.",
                            })
                    except Exception as e:
                        logger.warning(f"DAG plan error: {e}")
                        # Fallback to simple plan mode
                        messages.append(
                            {"role": "assistant", "content": raw_response})
                        messages.append({
                            "role": "user",
                            "content": "–ü–ª–∞–Ω –ø—Ä–∏–Ω—è—Ç. –í—ã–ø–æ–ª–Ω—è–π –ø–æ—à–∞–≥–æ–≤–æ. –ù–∞—á–Ω–∏ —Å –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞. JSON —Ñ–æ—Ä–º–∞—Ç.",
                        })

                else:
                    # Unknown type ‚Äî nudge to continue
                    messages.append(
                        {"role": "assistant", "content": raw_response})
                    messages.append({
                        "role": "user",
                        "content": "–ü—Ä–æ–¥–æ–ª–∂–∞–π. –í—ã–ø–æ–ª–Ω–∏ –¥–µ–π—Å—Ç–≤–∏–µ –∏–ª–∏ –¥–∞–π final_answer. JSON —Ñ–æ—Ä–º–∞—Ç.",
                    })

            except Exception as e:
                logger.error(
                    f"Agent error iter={iteration}: {e}\n{traceback.format_exc()}")
                step.observation = f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {e}"

                # Failure-driven learning
                try:
                    self._adv_memory.store_failure(
                        content=f"–û—à–∏–±–∫–∞: {str(e)[:200]}",
                        error_context=f"–ó–∞–ø—Ä–æ—Å: {message[:100]}",
                        correction="", severity="medium",
                        tags=["agent_error", "runtime"], chat_id=chat_id,
                    )
                except Exception:
                    pass

                messages.append({
                    "role": "user",
                    "content": (
                        f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}. "
                        f"–ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥ –∏–ª–∏ –¥–∞–π final_answer. JSON —Ñ–æ—Ä–º–∞—Ç."
                    ),
                })

            step.duration_ms = int((time.time() - step_start) * 1000)
            steps.append(step)

        # Exceeded max iterations ‚Äî force final answer
        logger.warning(f"Agent: exceeded {self.MAX_ITERATIONS} iterations")
        fallback = await self._force_final_answer(message, messages)

        return AgentResponse(
            answer=_clean_json_from_response(fallback),
            steps=steps, tools_used=tools_used,
            total_iterations=self.MAX_ITERATIONS,
            total_time_ms=int((time.time() - start_time) * 1000),
            memory_entries_created=memory_entries,
            files_to_send=files_to_send,
        )

    # ‚îÄ‚îÄ‚îÄ Smart Routing v3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def _execute_complex_task(
        self,
        message: str,
        chat_id: int,
        db_session,
        start_time: float,
    ) -> AgentResponse | None:
        """
        v4: Automatic DAG execution for complex multi-step tasks.

        1. Generate DAG plan via CognitiveEngine
        2. Execute nodes in parallel via ParallelDAGExecutor
        3. Self-correct on failures
        4. Compile results into coherent answer

        Returns AgentResponse if successful, None to fall back to ReAct.
        """
        logger.info("Agent v4: complex task detected, generating DAG plan")

        # Generate DAG plan
        tools_desc = self._tools.get_tools_prompt()
        dag_plan = await self._cognitive.generate_plan(
            goal=message,
            tools_description=tools_desc,
            llm_engine=self.llm,
        )

        if not dag_plan or len(dag_plan.nodes) <= 1:
            return None  # Not complex enough for DAG

        logger.info(
            f"Agent v4: DAG plan with {len(dag_plan.nodes)} nodes, "
            f"groups: {dag_plan.get_parallel_groups()}"
        )

        # Execute DAG
        tools_used = []
        files_to_send = []
        steps = []

        async def _dag_executor(
            node_id: str,
            tool_name: str | None,
            tool_params: dict | None,
        ) -> str:
            if not tool_name:
                # LLM-only node ‚Äî use direct reasoning
                node = dag_plan.nodes.get(node_id)
                desc = node.description if node else node_id
                try:
                    result = await self.llm.chat(
                        message=f"–í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞—á—É: {desc}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {message}",
                        task_type="simple_answer",
                        temperature=0.5,
                        max_tokens=1024,
                    )
                    return result
                except Exception as e:
                    return f"–û—à–∏–±–∫–∞: {e}"

            matched = self._fuzzy_match_tool(tool_name) or tool_name
            result = await self._tools.execute(
                matched, tool_params or {}, db_session
            )
            tools_used.append(matched)
            if (result.success
                    and isinstance(result.data, dict)
                    and result.data.get("send_file")):
                files_to_send.append({
                    "filepath": result.data.get("filepath", ""),
                    "filename": result.data.get("filename", ""),
                })
            return str(result)

        try:
            dag_results = await parallel_engine.dag_executor.execute_dag(
                dag_plan, _dag_executor
            )
        except Exception as e:
            logger.warning(f"DAG execution failed: {e}")
            return None

        # Self-correction for failed nodes
        failed_nodes = [r for r in dag_results if not r.success]
        if failed_nodes:
            for failed in failed_nodes:
                try:
                    dag_plan = await self._cognitive.self_correct_plan(
                        dag_plan,
                        failed.task_id,
                        failed.error or "Unknown error",
                        llm_engine=self.llm,
                    )
                except Exception:
                    pass

        # Compile results
        result_parts = []
        for r in dag_results:
            node = dag_plan.nodes.get(r.task_id)
            desc = node.description if node else r.task_id
            icon = "‚úÖ" if r.success else "‚ùå"
            result_text = str(r.result)[:500] if r.result else r.error or ""
            result_parts.append(f"{icon} {desc}: {result_text}")

        # Generate coherent answer from all results
        compilation_prompt = (
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ø—Ä–æ—Å–∏–ª: {message}\n\n"
            f"–í—ã–ø–æ–ª–Ω–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n"
            + "\n".join(result_parts) +
            "\n\n–°–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–∏–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º. "
            "–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π JSON. –¢–æ–ª—å–∫–æ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç."
        )

        try:
            answer = await self.llm.chat(
                message=compilation_prompt,
                task_type="simple_answer",
                temperature=0.5,
                max_tokens=2048,
            )
            answer = _clean_json_from_response(answer)
        except Exception:
            answer = "\n".join(result_parts)

        step = AgentStep(
            iteration=1,
            thought=f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ DAG-–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {len(dag_plan.nodes)} —à–∞–≥–æ–≤",
            observation=dag_plan.get_summary(),
            duration_ms=int((time.time() - start_time) * 1000),
        )
        steps.append(step)

        return AgentResponse(
            answer=answer,
            steps=steps,
            tools_used=tools_used,
            total_iterations=1,
            total_time_ms=int((time.time() - start_time) * 1000),
            plan_used=True,
            files_to_send=files_to_send,
        )

    async def should_use_tools(self, message: str) -> bool:
        """
        v3: Adaptive routing ‚Äî keywords + semantic signals.
        Fast-path for simple messages, tool-path for complex ones.
        """
        lower = message.lower().strip()

        # Fast reject: greetings, thanks, simple chat
        simple_patterns = [
            "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–∫–∞–∫ –¥–µ–ª–∞", "—Å–ø–∞—Å–∏–±–æ", "–ø–æ–∫–∞",
            "—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å", "–∫—Ç–æ —Ç—ã", "–ø–æ–º–æ—â—å", "–¥–æ–±—Ä", "—Å–∞–ª–∞–º",
            "—Ö–æ—Ä–æ—à–æ", "–æ–∫", "–ø–æ–Ω—è—Ç–Ω–æ", "—è—Å–Ω–æ", "–ª–∞–¥–Ω–æ", "–¥–∞", "–Ω–µ—Ç",
            "hello", "hi", "thanks", "bye", "good",
        ]
        # Exact match or starts with
        if lower in simple_patterns or any(lower.startswith(p) and len(lower) < len(p) + 15 for p in simple_patterns):
            # But if it also has tool keywords, route to tools
            if not any(p in lower for p in ["–∑–∞–∫–∞–∑", "—Ñ–∞–π–ª", "excel", "–æ—Ç–ø—Ä–∞–≤", "—Å–æ–∑–¥–∞"]):
                return False

        # Tool-requiring patterns (comprehensive)
        tool_patterns = [
            # Orders & logistics
            "–∑–∞–∫–∞–∑", "–ø–æ–∑–∏—Ü", "—Ç—Ä–µ–∫", "–¥–æ—Å—Ç–∞–≤–∫", "—Ç–æ–≤–∞—Ä", "—Å–∫–ª–∞–¥",
            # Finance
            "–±–∞–ª–∞–Ω—Å", "–ø—Ä–∏–±—ã–ª", "–¥–æ—Ö–æ–¥", "—Ä–∞—Å—Ö–æ–¥", "—Ñ–∏–Ω–∞–Ω—Å", "–∫—É—Ä—Å", "–≤–∞–ª—é—Ç", "–∫–æ–Ω–≤–µ—Ä—Ç",
            "–æ–ø–ª–∞—Ç", "–ø–ª–∞—Ç", "–¥–µ–Ω–µ–≥", "–¥–µ–Ω—å–≥", "—Å—É–º–º", "—Å—Ç–æ–∏–º–æ—Å—Ç", "—Ü–µ–Ω",
            # Files & documents
            "—Ñ–∞–π–ª", "excel", "xls", "pdf", "word", "docx", "—Ç–∞–±–ª–∏—Ü", "–¥–æ–∫—É–º–µ–Ω—Ç",
            "csv", "–æ—Ç—á—ë—Ç", "–æ—Ç—á–µ—Ç",
            # Creation
            "—Å–æ–∑–¥–∞–π", "—Å–¥–µ–ª–∞–π", "—Å–≥–µ–Ω–µ—Ä–∏—Ä", "–ø–æ—Å—Ç—Ä–æ–π", "—Å–æ—Å—Ç–∞–≤—å", "–ø–æ–¥–≥–æ—Ç–æ–≤—å",
            # Calendar & reminders
            "–Ω–∞–ø–æ–º–Ω–∏", "–≤—Å—Ç—Ä–µ—á", "–∫–∞–ª–µ–Ω–¥", "—Å–æ–±—ã—Ç–∏", "—Ä–∞—Å–ø–∏—Å–∞–Ω",
            # Contacts & CRM
            "–∫–æ–Ω—Ç–∞–∫—Ç", "–ø–æ—Å—Ç–∞–≤—â–∏–∫", "–∫–ª–∏–µ–Ω—Ç", "–ø–∞—Ä—Ç–Ω—ë—Ä", "–ø–∞—Ä—Ç–Ω–µ—Ä",
            "vip", "—Ä–µ–π—Ç–∏–Ω–≥", "–æ—Ü–µ–Ω–∫",
            # Status & reports
            "—Å—Ç–∞—Ç—É—Å", "–±—Ä–∏—Ñ–∏–Ω–≥", "–¥–∞–π–¥–∂–µ—Å—Ç", "–∞–Ω–∞–ª–∏—Ç–∏–∫", "kpi", "–¥–∞—à–±–æ—Ä–¥",
            # Archive & backup
            "–∞—Ä—Ö–∏–≤", "–±—ç–∫–∞–ø", "—É–¥–∞–ª–∏",
            # Messaging
            "–æ—Ç–ø—Ä–∞–≤", "—Å–æ–æ–±—â–µ–Ω", "–Ω–∞–ø–∏—Å–∞", "–Ω–∞–ø–∏—à", "–ø–∏—à–∏", "—Å–∫–∞–∂–∏", "–ø–µ—Ä–µ–¥–∞–π",
            "–ø–æ–∑–≤–æ–Ω–∏", "–ø–æ—à–ª–∏",
            # Specific platforms
            "whatsapp", "–≤–æ—Ç—Å–∞–ø", "–≤–∞—Ç—Å–∞–ø", "–≤–∞—Ü–∞–ø",
            "telegram", "—Ç–µ–ª–µ–≥—Ä–∞–º",
            "email", "–ø–æ—á—Ç", "–ø–∏—Å—å–º", "gmail", "e-mail",
            # Mimicry & style
            "–º–∏–º–∏–∫—Ä", "—Å—Ç–∏–ª—å", "—Å–∫–∞–Ω",
            # Search & research
            "–Ω–∞–π–¥–∏", "–ø–æ–∏—Å–∫", "–ø–æ–∏—â–∏", "google", "–≥—É–≥–ª", "–∏—Å—Å–ª–µ–¥—É–π",
            "—É–∑–Ω–∞–π", "–ø—Ä–æ–≤–µ—Ä—å", "–ø—Ä–æ–≤–µ—Ä",
            # Translation
            "–ø–µ—Ä–µ–≤–µ–¥–∏", "–ø–µ—Ä–µ–≤–æ–¥", "–ø–µ—Ä–µ–≤–æ–¥—á",
            # Memory
            "–∑–∞–ø–æ–º–Ω–∏", "–≤—Å–ø–æ–º–Ω–∏", "–ø–æ–º–Ω",
            # Triggers & automation
            "—Ç—Ä–∏–≥–≥–µ—Ä", "–∞–ª–µ—Ä—Ç", "—É–≤–µ–¥–æ–º–ª", "–∞–≤—Ç–æ–º–∞—Ç",
            # System
            "—Å–∏—Å—Ç–µ–º", "–∑–¥–æ—Ä–æ–≤—å", "–∞–ø—Ç–∞–π–º",
            # Web & browsing
            "—Å–∞–π—Ç", "—Å—Ç—Ä–∞–Ω–∏—Ü", "url", "http", "browse", "web",
            "–æ—Ç–∫—Ä–æ–π", "–∑–∞–≥—Ä—É–∑–∏", "—Å–∫–∞—á–∞–π", "—Å—Å—ã–ª–∫",
            # v5: Files & sandbox
            "—Ñ–∞–π–ª", "–∫–æ–¥", "—Å–∫—Ä–∏–ø—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º", "—Ñ—É–Ω–∫—Ü–∏",
            "–ø—Ä–æ—á–∏—Ç–∞–π", "–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π", "–∏—Å–ø—Ä–∞–≤—å", "–¥–æ–±–∞–≤—å —Å—Ç—Ä–æ–∫",
            "–±—ç–∫–∞–ø", "—Å–æ–∑–¥–∞–π —Ñ–∞–π–ª", "–∑–∞–ø—É—Å—Ç–∏ –∫–æ–¥", "–≤—ã–ø–æ–ª–Ω–∏ –∫–æ–¥",
            "–ø–µ—Å–æ—á–Ω–∏—Ü", "sandbox",
            # v5: Data analysis
            "–¥–∞–Ω–Ω—ã–µ", "–¥–∞–Ω–Ω—ã—Ö", "–≥—Ä–∞—Ñ–∏–∫", "–¥–∏–∞–≥—Ä–∞–º–º", "–≥–∏—Å—Ç–æ–≥—Ä–∞–º–º",
            "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫", "–∫–æ—Ä—Ä–µ–ª—è—Ü", "—Ñ–∏–ª—å—Ç—Ä", "–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫",
            "eda", "–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö", "—Ç–∞–±–ª–∏—Ü",
            # v5: Research
            "–∏—Å—Å–ª–µ–¥—É–π", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏", "—Å—Ä–∞–≤–Ω–∏",
            "wide research", "compare",
            # v6: Universal life patterns
            "—Ä–µ—Ü–µ–ø—Ç", "–º–∞—Ä—à—Ä—É—Ç", "–ø–æ–≥–æ–¥", "–ø–µ—Ä–µ–ª—ë—Ç", "—Ä–µ–π—Å",
            "–±–∏–ª–µ—Ç", "–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω", "–æ—Ç–µ–ª—å", "–≥–æ—Å—Ç–∏–Ω–∏—Ü",
            "–ª–µ–∫–∞—Ä—Å—Ç–≤", "–¥–∏–∞–≥–Ω–æ–∑", "—Å–∏–º–ø—Ç–æ–º", "—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫",
            "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏", "—Ä–∞—Å—á—ë—Ç", "–∫–∞–ª—å–∫—É–ª", "–∫–æ–Ω–≤–µ—Ä—Ç",
            "–ø–µ—Ä–µ–≤–æ–¥", "–ø–µ—Ä–µ–≤–µ–¥–∏", "–æ–±—ä—è—Å–Ω–∏", "–Ω–∞—É—á–∏",
            "—Å–≥–µ–Ω–µ—Ä–∏—Ä", "–Ω–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç", "—Å–æ—Å—Ç–∞–≤—å –ø–∏—Å—å–º–æ",
            "—Ä–µ—Ñ–µ—Ä–∞—Ç", "—ç—Å—Å–µ", "–ø–ª–∞–Ω –ø–æ–µ–∑–¥–∫–∏",
            # Username mention
            "@",
            # Contact book
            "–∫–æ–Ω—Ç–∞–∫—Ç", "–ø—Ä–∏–≤—è–∂", "–ø—Ä–∏–≤—è–∑–∫", "–∑–∞–ø–æ–º–Ω–∏ –Ω–æ–º–µ—Ä",
            "–∑–∞–ø–æ–º–Ω–∏ –ø–æ—á—Ç", "–∑–∞–ø–æ–º–Ω–∏ email", "–∑–∞–ø–æ–º–Ω–∏ —é–∑–µ—Ä–Ω–µ–π–º",
            "—é–∑–µ—Ä–Ω–µ–π–º", "username", "–Ω–∞–ø–∏—à–∏ ", "–æ—Ç–ø—Ä–∞–≤—å ",
            "–ø–æ–∑–≤–æ–Ω–∏", "–Ω–∞–ø–∏—Å–∞—Ç—å ", "–Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω", "–ø–æ—á—Ç",
        ]

        if any(p in lower for p in tool_patterns):
            return True

        # Long messages or messages with numbers likely need tools
        if len(message) > 120:
            return True
        if any(c.isdigit() for c in message) and len(message) > 20:
            return True

        # Questions about specific data
        question_words = ["—Å–∫–æ–ª—å–∫–æ", "–∫–∞–∫–æ–π", "–≥–¥–µ",
                          "–∫–æ–≥–¥–∞", "–∫–æ–º—É", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º"]
        if any(w in lower for w in question_words) and len(message) > 30:
            return True

        return False

    # ‚îÄ‚îÄ‚îÄ Direct Response (–±–µ–∑ tools) v3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def direct_response(
        self,
        message: str,
        history: list[dict[str, str]] | None = None,
        style_guide: str | None = None,
        chat_id: int | None = None,
    ) -> str:
        """
        v3: Fast direct response ‚Äî no ReAct overhead.
        Clean system prompt, no JSON mode, instant answer.
        """
        # Memory context
        memory_ctx = self._adv_memory.get_context_for_prompt(message)
        if not memory_ctx:
            memory_ctx = self._memory.get_context_for_prompt(message)

        time_ctx = self._adv_memory.get_time_context()
        if memory_ctx:
            memory_ctx = f"{memory_ctx}\n\n{time_ctx}"
        else:
            memory_ctx = time_ctx

        # v6: auto-style from persona
        if not style_guide:
            try:
                from pds_ultimate.core.persona_engine import persona_engine
                _cid = chat_id or config.telegram.owner_id
                style_guide = persona_engine.get_style_guide(_cid)
            except Exception:
                pass

        style_part = f"\n–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø: {style_guide}" if style_guide else ""
        system = (
            "–¢—ã ‚Äî PDS-Ultimate v6, —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π AI-–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç.\n"
            "–¢—ã ‚Äî –¥—Ä—É–≥, –ø—Ä–∞–≤–∞—è —Ä—É–∫–∞, –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ –≤–ª–∞–¥–µ–ª—å—Ü–∞.\n"
            "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –≤–æ –í–°–Å–ú: –±–∏–∑–Ω–µ—Å, –±—ã—Ç, –∑–¥–æ—Ä–æ–≤—å–µ, —É—á—ë–±–∞, —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è, –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è.\n"
            "–û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û –∏ –ø–æ –¥–µ–ª—É. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π JSON.\n"
            "–û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç—ã–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n"
            "–ù–ï –æ–±–æ—Ä–∞—á–∏–≤–∞–π –æ—Ç–≤–µ—Ç –≤ —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏ –∏–ª–∏ –∫–∞–≤—ã—á–∫–∏.\n"
            "–ö—É—Ä—Å—ã: 1 USD = 19.5 TMT, 1 USD = 7.1 CNY.\n"
            f"{memory_ctx}\n{style_part}"
        )

        response = await self.llm.chat(
            message=message,
            history=history,
            system_prompt=system,
            task_type="simple_answer",  # v3: use fast model
            temperature=0.7,
        )

        # v3: Safety clean
        return _clean_json_from_response(response)

    # ‚îÄ‚îÄ‚îÄ Internal Methods ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _build_system_prompt(
        self,
        message: str,
        working: WorkingMemory | AdvancedWorkingMemory,
        style_guide: str | None,
        extra_context: str = "",
        chat_id: int | None = None,
    ) -> str:
        """Build system prompt with tools and context."""
        tools_desc = self._tools.get_tools_prompt()

        memory_ctx = self._adv_memory.get_context_for_prompt(message)
        if not memory_ctx:
            memory_ctx = self._memory.get_context_for_prompt(message)

        working_ctx = working.get_context_summary()

        style_ctx = ""
        if style_guide:
            style_ctx = f"–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø –í–õ–ê–î–ï–õ–¨–¶–ê:\n{style_guide}"
        else:
            # v6: auto persona style
            try:
                from pds_ultimate.core.persona_engine import persona_engine
                _cid = chat_id or config.telegram.owner_id
                auto_style = persona_engine.get_style_guide(_cid)
                if auto_style:
                    style_ctx = auto_style
            except Exception:
                pass

        if extra_context:
            memory_ctx = f"{memory_ctx}\n\n{extra_context}" if memory_ctx else extra_context

        return AGENT_SYSTEM_PROMPT.format(
            tools_description=tools_desc or "[–ù–µ—Ç –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤]",
            memory_context=memory_ctx,
            working_context=working_ctx,
            style_context=style_ctx,
        )

    def _build_messages(
        self,
        message: str,
        history: list[dict[str, str]] | None,
        system_prompt: str,
    ) -> list[dict[str, str]]:
        """Build message array for LLM."""
        messages = [{"role": "system", "content": system_prompt}]
        if history:
            messages.extend(history[-20:])
        messages.append({"role": "user", "content": message})
        return messages

    async def _call_llm(self, messages: list[dict[str, str]]) -> str:
        """Call LLM with messages. Uses fast model for agent loop."""
        if not self.llm._client:
            await self.llm.start()

        payload = {
            "model": config.deepseek.fast_model,
            "messages": messages,
            "temperature": 0.3,
            "max_tokens": 2048,
            "stream": False,
            "response_format": {"type": "json_object"},
        }

        try:
            response = await self.llm._client.post(
                "/v1/chat/completions",
                json=payload,
            )
            response.raise_for_status()
            data = response.json()
            content = data["choices"][0]["message"]["content"]
            return content.strip()
        except Exception as e:
            logger.error(f"Agent LLM call error: {e}")
            raise

    def _parse_response(self, raw: str) -> AgentAction:
        """
        v3: Robust JSON parsing with fallbacks.
        Handles malformed JSON, missing fields, wrong types.
        """
        try:
            data = json.loads(raw)
        except json.JSONDecodeError:
            data = self._extract_json(raw)
            if not data:
                # Not JSON ‚Äî treat as final answer
                return AgentAction(
                    action_type="final_answer",
                    thought="(–æ—Ç–≤–µ—Ç –±–µ–∑ JSON)",
                    answer=raw,
                    confidence=0.5,
                )

        thought = str(data.get("thought", ""))
        confidence = 0.5
        try:
            confidence = float(data.get("confidence", 0.5))
        except (ValueError, TypeError):
            pass

        action_data = data.get("action", {})
        if isinstance(action_data, str):
            return AgentAction(
                action_type="final_answer",
                thought=thought,
                answer=action_data,
                confidence=confidence,
            )

        if not isinstance(action_data, dict):
            # Fallback: check if there's an answer field at top level
            top_answer = data.get("answer", "")
            if top_answer:
                return AgentAction(
                    action_type="final_answer",
                    thought=thought,
                    answer=str(top_answer),
                    confidence=confidence,
                )
            return AgentAction(
                action_type="final_answer",
                thought=thought,
                answer=thought or raw,
                confidence=confidence,
            )

        action_type = action_data.get("type", "final_answer")

        # v3: Handle parallel_tools
        parallel_calls = None
        if action_type == "parallel_tools":
            calls = action_data.get("calls", [])
            if isinstance(calls, list) and calls:
                parallel_calls = calls
            else:
                # Fallback to single tool
                action_type = "tool_call"

        action = AgentAction(
            action_type=action_type,
            tool_name=action_data.get("tool"),
            tool_params=action_data.get("params", {}),
            thought=thought,
            answer=str(action_data.get("answer", "")),
            confidence=confidence,
            parallel_calls=parallel_calls,
        )

        # Memory
        should_remember = data.get("should_remember")
        if should_remember and isinstance(should_remember, str) and should_remember.lower() != "null":
            action._should_remember = should_remember
        else:
            action._should_remember = None

        return action

    def _extract_json(self, text: str) -> dict | None:
        """Extract JSON from text with multiple strategies."""
        # Strategy 1: ```json ... ```
        match = re.search(r"```(?:json)?\s*([\s\S]*?)```", text)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass

        # Strategy 2: Find outermost {...}
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                pass

        # Strategy 3: Try to fix common JSON issues
        # Missing quotes, trailing commas
        cleaned = text.strip()
        if cleaned.startswith("{"):
            # Remove trailing commas before }
            cleaned = re.sub(r',\s*}', '}', cleaned)
            cleaned = re.sub(r',\s*]', ']', cleaned)
            try:
                return json.loads(cleaned)
            except json.JSONDecodeError:
                pass

        return None

    async def _self_reflect(
        self,
        original_query: str,
        answer: str,
        steps: list[AgentStep],
        working: WorkingMemory,
    ) -> str:
        """
        Self-reflection: evaluate and optionally improve answer.
        v3: Only for complex multi-step answers.
        """
        reflection_prompt = (
            f"–û—Ü–µ–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞.\n"
            f"–ó–ê–ü–†–û–°: {original_query}\n"
            f"–û–¢–í–ï–¢: {answer}\n"
            f"–®–ê–ì–û–í: {len(steps)}\n"
            f"–í–µ—Ä–Ω–∏ JSON: {{\"quality\": 0.0-1.0, \"improved_answer\": \"...\" –∏–ª–∏ null}}"
        )

        try:
            raw = await self.llm.chat(
                message=reflection_prompt,
                task_type="simple_answer",
                temperature=0.2,
                json_mode=True,
                max_tokens=2048,
            )

            data = json.loads(raw)
            quality = float(data.get("quality", 0.8))

            if quality < 0.6 and data.get("improved_answer"):
                logger.info(
                    f"Self-reflection: quality={quality:.1f}, improving")
                improved = str(data["improved_answer"])
                return _clean_json_from_response(improved)

            return answer

        except Exception as e:
            logger.warning(f"Self-reflection error: {e}")
            return answer

    async def _force_final_answer(
        self,
        original_message: str,
        messages: list[dict[str, str]],
    ) -> str:
        """Force a final answer after exceeding iteration limit."""
        messages.append({
            "role": "user",
            "content": (
                "–°–¢–û–ü. –õ–∏–º–∏—Ç –∏—Ç–µ—Ä–∞—Ü–∏–π. –î–∞–π –§–ò–ù–ê–õ–¨–ù–´–ô –æ—Ç–≤–µ—Ç –ü–†–Ø–ú–û –°–ï–ô–ß–ê–°. "
                "–ò—Å–ø–æ–ª—å–∑—É–π —Å–æ–±—Ä–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –û—Ç–≤–µ—Ç—å –û–ë–´–ß–ù–´–ú –¢–ï–ö–°–¢–û–ú, –ù–ï JSON."
            ),
        })

        try:
            if not self.llm._client:
                await self.llm.start()

            payload = {
                "model": config.deepseek.fast_model,
                "messages": messages,
                "temperature": 0.5,
                "max_tokens": 2048,
                "stream": False,
                # v3: NO json_mode here ‚Äî we want plain text
            }

            response = await self.llm._client.post(
                "/v1/chat/completions",
                json=payload,
            )
            response.raise_for_status()
            data = response.json()
            raw = data["choices"][0]["message"]["content"].strip()
            return _clean_json_from_response(raw)

        except Exception as e:
            logger.error(f"Force final answer error: {e}")
            return "–ò–∑–≤–∏–Ω–∏, –≤–æ–∑–Ω–∏–∫–ª–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."

    # ‚îÄ‚îÄ‚îÄ Background Memory Extraction ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def background_extract_memories(
        self,
        dialogue: str,
        db_session=None,
        chat_id: int | None = None,
    ) -> int:
        """Background fact extraction after sending response."""
        try:
            entries = await self._adv_memory.extract_and_store_facts(
                dialogue, self.llm, chat_id=chat_id,
            )
            old_entries = await self._memory.extract_and_store_facts(
                dialogue, self.llm,
            )

            if entries and db_session:
                self._adv_memory.save_to_db(db_session)
            if old_entries and db_session:
                self._memory.save_to_db(db_session)

            return len(entries) + len(old_entries)
        except Exception as e:
            logger.warning(f"Background memory extraction error: {e}")
            return 0


# ‚îÄ‚îÄ‚îÄ Global instance ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

agent = Agent()
